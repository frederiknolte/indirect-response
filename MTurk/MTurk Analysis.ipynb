{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "a72d442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, linregress\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from krippendorff_alpha import krippendorff_alpha, nominal_metric, interval_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4c5ff",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "84ee866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_csv = \"final_results.csv\"\n",
    "las_csv = \"las_13_unmatched_simulator_results/LAS_nli_relaxed_unmatched13_test_data_circa_NLI_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02e18c",
   "metadata": {},
   "source": [
    "Load inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "89274013",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = pd.read_csv(\"originalmturk_explain_unmatched.csv\", dtype=object)\n",
    "inputs2 = pd.read_csv(\"originalmturk_explain_unmatched2.csv\", dtype=object)\n",
    "inputs = pd.concat([inputs1, inputs2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc58cc5",
   "metadata": {},
   "source": [
    "Load results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "8d5f2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(result_csv, sep=',', dtype=object, escapechar='\\\\', engine='python',\n",
    "                      usecols=['WorkerId',\n",
    "                               'Input.context',\n",
    "                               'Input.question',\n",
    "                               'Input.answer',\n",
    "                               'Input.explanation',\n",
    "                               'Input.interpretation',\n",
    "                               'Answer.explanation-quality.label',\n",
    "                               'WorkTimeInSeconds']\n",
    "                      )\n",
    "results.columns = ['WorkerId', 'WorkTimeInSeconds', 'context', 'question',\n",
    "                   'answer', 'explanation', 'shown_target',\n",
    "                   'annotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324cbe62",
   "metadata": {},
   "source": [
    "Load LAS data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "8852075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "las = pd.read_csv(las_csv, \n",
    "            dtype=object, escapechar='\\\\', index_col=0\n",
    "                 )\n",
    "las.columns = ['context', 'hypothesis', 'answer', \n",
    "               'target', 'prediction', 'explanation', \n",
    "               'XE_pred','XE_prob','X_pred',\n",
    "               'X_prob','E_pred','E_prob',\n",
    "               'leaked']\n",
    "las.drop(['context'], axis=1, inplace=True)\n",
    "las.drop(['leaked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ade2ab",
   "metadata": {},
   "source": [
    "## Clean columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52c0f6",
   "metadata": {},
   "source": [
    "Make columns numerical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "35530a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['annotation'].replace('5 - very good', 5, inplace=True)\n",
    "results['annotation'].replace('1 - very poor', 1, inplace=True)\n",
    "results.annotation = results.annotation.astype(int)\n",
    "results.WorkTimeInSeconds = results.WorkTimeInSeconds.astype(int)\n",
    "\n",
    "las['target'] = las['target'].astype(int)\n",
    "las['prediction'] = las['prediction'].astype(int)\n",
    "las['XE_pred'] = las['XE_pred'].astype(int)\n",
    "las['E_pred'] = las['E_pred'].astype(int)\n",
    "las['X_pred'] = las['X_pred'].astype(int)\n",
    "las['target'] = las.target.map({0:'Middle', \n",
    "                                1:'Yes', \n",
    "                                2:'No', \n",
    "                                3:'none'\n",
    "                               })\n",
    "las['prediction'] = las.prediction.map({0:'Middle', \n",
    "                                        1:'Yes', \n",
    "                                        2:'No', \n",
    "                                        3:'none'\n",
    "                                       })\n",
    "las['XE_pred'] = las.XE_pred.map({0:'Middle', \n",
    "                                  1:'Yes', \n",
    "                                  2:'No', \n",
    "                                  3:'none'\n",
    "                                 })\n",
    "las['E_pred'] = las.E_pred.map({0:'Middle', \n",
    "                                1:'Yes', \n",
    "                                2:'No', \n",
    "                                3:'none'\n",
    "                               })\n",
    "las['X_pred'] = las.X_pred.map({0:'Middle', \n",
    "                                1:'Yes', \n",
    "                                2:'No', \n",
    "                                3:'none'\n",
    "                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c29522",
   "metadata": {},
   "source": [
    "Match dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "67fa0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = inputs.merge(\n",
    "        results,\n",
    "        on=[\"context\", \"question\", \"answer\", \"explanation\"],\n",
    "        how=\"right\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3b697",
   "metadata": {},
   "source": [
    "Add additional information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "b65a53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['corr_target_shown'] = data['target'] == data['shown_target']\n",
    "data = data.replace('In the middle, neither yes nor no', 'Middle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd39c8d",
   "metadata": {},
   "source": [
    "Drop irrelevant columns and add indicator for correct prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "a602a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['exclude', \n",
    "           'goldstandard1', \n",
    "           'correct_pred', \n",
    "           'interpretation'], axis=1, inplace=True)\n",
    "data['correct_pred'] = data['target'] == data['prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738bd08",
   "metadata": {},
   "source": [
    "Merge with LAS data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "37d5c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(\n",
    "        las,\n",
    "        on=[\"hypothesis\", \"target\", \"prediction\", \"explanation\", \"answer\"],\n",
    "        how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e7b98",
   "metadata": {},
   "source": [
    "Add LAS-specific information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "id": "52f11a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['XE_correct'] = data['XE_pred'] == data['prediction']\n",
    "data['E_correct'] = data['E_pred'] == data['prediction']\n",
    "data['X_correct'] = data['X_pred'] == data['prediction']\n",
    "data['LAS_score'] = data['XE_correct'].astype(int) - data['X_correct'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166a179",
   "metadata": {},
   "source": [
    "Total number of annotations (not yet checked for 3 annotations per item):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "56e10654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48828ca3",
   "metadata": {},
   "source": [
    "Remove items with less than 3 annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "164f4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_annotations = data[['id', 'corr_target_shown', 'WorkerId']].groupby(['id', 'corr_target_shown']).agg({'WorkerId': ['count']})\n",
    "num_annotations.columns = ['num_annotations']\n",
    "data = data.merge(num_annotations, how='left', on=['id', 'corr_target_shown'])\n",
    "data = data[data['num_annotations'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b6d8c",
   "metadata": {},
   "source": [
    "Remove wrongly formatted sample identified during the survey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "id": "c07fffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['id'] != '17777']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f375d4ba",
   "metadata": {},
   "source": [
    "# Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "5a5b0a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique samples: 71\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique samples: {len(pd.unique(data['id']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04952452",
   "metadata": {},
   "source": [
    "Number of remaining annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "db017571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "10d874e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hypothesis', 'answer', 'target', 'prediction', 'explanation', 'leaked',\n",
       "       'id', 'context', 'question', 'judgements', 'WorkerId',\n",
       "       'WorkTimeInSeconds', 'shown_target', 'annotation', 'corr_target_shown',\n",
       "       'correct_pred', 'XE_pred', 'XE_prob', 'X_pred', 'X_prob', 'E_pred',\n",
       "       'E_prob', 'XE_correct', 'E_correct', 'X_correct', 'LAS_score',\n",
       "       'num_annotations'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15340c9",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e8b43",
   "metadata": {},
   "source": [
    "## Worker normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aafcd9",
   "metadata": {},
   "source": [
    "The following process normalizes the annotations using the average intra-worker mean \n",
    "and the average intra-worker standard deviation. This process ensures that systematic \n",
    "differences between workers (e.g. one worker tends to rate lower vs. the other tends \n",
    "to rate higher) are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e390940",
   "metadata": {},
   "source": [
    "Calculate average intra-worker mean and average intra-worker standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "6f51ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_mean = data.groupby(['WorkerId']).agg({'annotation': ['mean']}).mean().to_numpy()[0]\n",
    "annotation_std = data.groupby(['WorkerId']).agg({'annotation': ['std']}).mean().to_numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6a556",
   "metadata": {},
   "source": [
    "Center each annotation with the difference of the intra-worker mean of the worker who annotated it to the average intra-worker mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "8c540605",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = data.groupby(['WorkerId']).agg({'annotation': ['mean']})\n",
    "agg_data.columns = ['worker_mean']\n",
    "agg_data['mean_diff'] = annotation_mean - agg_data['worker_mean']\n",
    "agg_data.drop(['worker_mean'], axis=1, inplace=True)\n",
    "data = data.merge(agg_data, how='left', on=['WorkerId'])\n",
    "data['centered_annotation'] = data['annotation'] + data['mean_diff']\n",
    "data.drop(['mean_diff'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d5589",
   "metadata": {},
   "source": [
    "Divide each annotation by the intra-worker standard deviation of the worker who annotated it and multiply by the average intra-worker standard deviation to have all workers have the same standard deviation when annotating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "99eb40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = data.groupby(['WorkerId']).agg({'annotation': ['std']})\n",
    "agg_data.columns = ['worker_std']\n",
    "agg_data['std_ratio'] = annotation_std / agg_data['worker_std']\n",
    "agg_data.drop(['worker_std'], axis=1, inplace=True)\n",
    "data = data.merge(agg_data, how='left', on=['WorkerId'])\n",
    "data['normalized_annotation'] = data['centered_annotation'] * data['std_ratio']\n",
    "data.drop(['std_ratio'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d612b",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2cb85",
   "metadata": {},
   "source": [
    "### First an aggregation of worker annotations by label leakage, whether the model made the correct prediction and whether or not the correct target was shown to the annotators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "2f2d2179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">annotation</th>\n",
       "      <th colspan=\"3\" halign=\"left\">normalized_annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaked</th>\n",
       "      <th>correct_pred</th>\n",
       "      <th>corr_target_shown</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">No</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>False</th>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.612235</td>\n",
       "      <td>42</td>\n",
       "      <td>2.744472</td>\n",
       "      <td>1.575762</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1.844444</td>\n",
       "      <td>1.223920</td>\n",
       "      <td>45</td>\n",
       "      <td>1.960049</td>\n",
       "      <td>1.076572</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th>True</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.609630</td>\n",
       "      <td>45</td>\n",
       "      <td>3.130498</td>\n",
       "      <td>1.442543</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Yes</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>False</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.279204</td>\n",
       "      <td>45</td>\n",
       "      <td>2.123430</td>\n",
       "      <td>1.204365</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1.921569</td>\n",
       "      <td>1.230336</td>\n",
       "      <td>51</td>\n",
       "      <td>2.083960</td>\n",
       "      <td>1.216023</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th>True</th>\n",
       "      <td>3.416667</td>\n",
       "      <td>1.431536</td>\n",
       "      <td>72</td>\n",
       "      <td>3.641573</td>\n",
       "      <td>1.462699</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      annotation                  \\\n",
       "                                            mean       std count   \n",
       "leaked correct_pred corr_target_shown                              \n",
       "No     False        False               2.714286  1.612235    42   \n",
       "                    True                1.844444  1.223920    45   \n",
       "       True         True                3.000000  1.609630    45   \n",
       "Yes    False        False               2.000000  1.279204    45   \n",
       "                    True                1.921569  1.230336    51   \n",
       "       True         True                3.416667  1.431536    72   \n",
       "\n",
       "                                      normalized_annotation                  \n",
       "                                                       mean       std count  \n",
       "leaked correct_pred corr_target_shown                                        \n",
       "No     False        False                          2.744472  1.575762    42  \n",
       "                    True                           1.960049  1.076572    45  \n",
       "       True         True                           3.130498  1.442543    45  \n",
       "Yes    False        False                          2.123430  1.204365    45  \n",
       "                    True                           2.083960  1.216023    51  \n",
       "       True         True                           3.641573  1.462699    72  "
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['leaked', 'correct_pred', 'corr_target_shown']).agg({'annotation': ['mean', 'std', 'count'], 'normalized_annotation': ['mean', 'std', 'count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c4f2e4",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "We see that if the model produces the correct prediction (and the prediction is consequently shown), the rating of the qualtiy of rationales is the highest for both leaking and non-leaking rationales.\n",
    "\n",
    "Insterestingly, we see that showing the prediction instead of the true target for leaking rationales results only in a slight increase of rationale quality. This indicates that the model is not very faithful if the rationale is leaking. \n",
    "\n",
    "On the contrary, showing the prediction instead of the true target for non-leaking rationales results in a heavy increase of perceived rationale quality. This suggests that the model is highly faithful for non-leaking rationales.\n",
    "\n",
    "This *could* be explained by the following: We suppose that wrong model predictions are easily identifiable by human annotators. If rationales are leaking, they contain hints towards the predicted label as predicted by the model. If that prediction is wrong, this similarity to the label lets the rationale appear erroneous to the annotators. \n",
    "However, we asked annotators to judge the quality of rationales towards the shown label, no matter if that label is correct or incorrect.\n",
    "\n",
    "At the same time, if a rationale is marked as non-leaking, it does not contain strong hints towards the predicted label and thus if the predicted label does not coincide with the true label, the above effect is less severe, i.e. the rationale does not appear as bad as if it contained hints towards a wrong prediction.\n",
    "\n",
    "This suggests that annotators disregarded the annotation instructions and rated the prediction and rationale jointly instead of the rationale only. This makes general statements about faithfulness difficult and restricts us to be able to make statements about model faithfulness in the non-leaking case.\n",
    "\n",
    "To confirm, I asked the annotators that I know how they annotated the samples and they indeed confirmed having rated the prediction as well as the rationales. When showing them how the instructions actually stated the task, they admitted that this would change a lot of their annotations.\n",
    "\n",
    "Key takeaway from this table is that we would probably need to adapt the survey setup if we go for a more extensive human evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b45d3c",
   "metadata": {},
   "source": [
    "### Now a simple aggregation of the worker annotations by label-leakage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "7f763a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">annotation</th>\n",
       "      <th colspan=\"3\" halign=\"left\">normalized_annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaked</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>2.515152</td>\n",
       "      <td>1.560411</td>\n",
       "      <td>132</td>\n",
       "      <td>2.608655</td>\n",
       "      <td>1.452351</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>2.583333</td>\n",
       "      <td>1.510112</td>\n",
       "      <td>168</td>\n",
       "      <td>2.762081</td>\n",
       "      <td>1.522605</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotation                 normalized_annotation                \n",
       "             mean       std count                  mean       std count\n",
       "leaked                                                                 \n",
       "No       2.515152  1.560411   132              2.608655  1.452351   132\n",
       "Yes      2.583333  1.510112   168              2.762081  1.522605   168"
      ]
     },
     "execution_count": 969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['leaked']).agg({'annotation': ['mean', 'std', 'count'], 'normalized_annotation': ['mean', 'std', 'count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0251ef3",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "We can see that leaking rationales are perceived to be slightly better than non-leaking rationales. However, this could be due to leaking rationales with correct predictions, which are the highest-rated rationales, being more common in the data, as can be observed in the previous table. We confirm by adding one level of aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "380a50fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">annotation</th>\n",
       "      <th colspan=\"3\" halign=\"left\">normalized_annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaked</th>\n",
       "      <th>correct_pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">No</th>\n",
       "      <th>False</th>\n",
       "      <td>2.264368</td>\n",
       "      <td>1.482140</td>\n",
       "      <td>87</td>\n",
       "      <td>2.338736</td>\n",
       "      <td>1.390030</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.609630</td>\n",
       "      <td>45</td>\n",
       "      <td>3.130498</td>\n",
       "      <td>1.442543</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Yes</th>\n",
       "      <th>False</th>\n",
       "      <td>1.958333</td>\n",
       "      <td>1.247454</td>\n",
       "      <td>96</td>\n",
       "      <td>2.102462</td>\n",
       "      <td>1.204355</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3.416667</td>\n",
       "      <td>1.431536</td>\n",
       "      <td>72</td>\n",
       "      <td>3.641573</td>\n",
       "      <td>1.462699</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    annotation                 normalized_annotation  \\\n",
       "                          mean       std count                  mean   \n",
       "leaked correct_pred                                                    \n",
       "No     False          2.264368  1.482140    87              2.338736   \n",
       "       True           3.000000  1.609630    45              3.130498   \n",
       "Yes    False          1.958333  1.247454    96              2.102462   \n",
       "       True           3.416667  1.431536    72              3.641573   \n",
       "\n",
       "                                     \n",
       "                          std count  \n",
       "leaked correct_pred                  \n",
       "No     False         1.390030    87  \n",
       "       True          1.442543    45  \n",
       "Yes    False         1.204355    96  \n",
       "       True          1.462699    72  "
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['leaked', 'correct_pred']).agg({'annotation': ['mean', 'std', 'count'], 'normalized_annotation': ['mean', 'std', 'count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd7aec",
   "metadata": {},
   "source": [
    "Indeed, while false predictions are roughly equally common for leaking and non-leaking rationales, we have significantly more correct predictions for leaking rationales than for non-leaking rationales. Again as mentioned before, correct predictions of leaking rationales are rated higher than predictions of non-leaking rationales. \n",
    "\n",
    "This result is nothing new and has already been discussed in the previous observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7357c1b1",
   "metadata": {},
   "source": [
    "### We now aggregate the annotations by which target was shown and whether the shown target was the ground truth target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "fdec7da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">annotation</th>\n",
       "      <th colspan=\"3\" halign=\"left\">normalized_annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shown_target</th>\n",
       "      <th>corr_target_shown</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Middle</th>\n",
       "      <th>False</th>\n",
       "      <td>3.111111</td>\n",
       "      <td>1.604732</td>\n",
       "      <td>18</td>\n",
       "      <td>3.100163</td>\n",
       "      <td>1.405394</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2.238095</td>\n",
       "      <td>1.513432</td>\n",
       "      <td>21</td>\n",
       "      <td>2.196586</td>\n",
       "      <td>1.260922</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">No</th>\n",
       "      <th>False</th>\n",
       "      <td>1.939394</td>\n",
       "      <td>1.390580</td>\n",
       "      <td>33</td>\n",
       "      <td>1.991860</td>\n",
       "      <td>1.341462</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.350822</td>\n",
       "      <td>90</td>\n",
       "      <td>2.448663</td>\n",
       "      <td>1.425252</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Yes</th>\n",
       "      <th>False</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.393864</td>\n",
       "      <td>36</td>\n",
       "      <td>2.480220</td>\n",
       "      <td>1.397314</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3.107843</td>\n",
       "      <td>1.585247</td>\n",
       "      <td>102</td>\n",
       "      <td>3.245508</td>\n",
       "      <td>1.511061</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               annotation                  \\\n",
       "                                     mean       std count   \n",
       "shown_target corr_target_shown                              \n",
       "Middle       False               3.111111  1.604732    18   \n",
       "             True                2.238095  1.513432    21   \n",
       "No           False               1.939394  1.390580    33   \n",
       "             True                2.200000  1.350822    90   \n",
       "Yes          False               2.333333  1.393864    36   \n",
       "             True                3.107843  1.585247   102   \n",
       "\n",
       "                               normalized_annotation                  \n",
       "                                                mean       std count  \n",
       "shown_target corr_target_shown                                        \n",
       "Middle       False                          3.100163  1.405394    18  \n",
       "             True                           2.196586  1.260922    21  \n",
       "No           False                          1.991860  1.341462    33  \n",
       "             True                           2.448663  1.425252    90  \n",
       "Yes          False                          2.480220  1.397314    36  \n",
       "             True                           3.245508  1.511061   102  "
      ]
     },
     "execution_count": 971,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['shown_target', 'corr_target_shown']).agg({'annotation': ['mean', 'std', 'count'], 'normalized_annotation': ['mean', 'std', 'count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c9625",
   "metadata": {},
   "source": [
    "Firstly, we note that there is a heavy imbalance between the number of datapoints we have for correctly shown targets 'YES' and 'NO' and all other possible configurations. \n",
    "\n",
    "Interesting observation:\n",
    "\n",
    "It appears that the model is better at producing rationales that support the target 'Yes' than it is at producing rationales that support the target 'No'. This can be seen in higher ratings for correctly shown targets 'Yes' than correctly shown targets 'No'. However from this table, we do not know what target the model predicted in both cases and can therefore not draw a definite conclusion from this yet. Maybe the model predicted more samples with shown target 'Yes' correctly than with shown target 'No' and due to a potential lack of faithfulness the ratings are higher in the former scenario. Unfortunately, due to the small number of annotations, we cannot make any conclusions when further grouping by model prediction.\n",
    "\n",
    "This is further supported by having higher ratings for incorrectly showing targets 'Yes' than for incorrectly showing targets 'No'. This suggests that generated rationales align better with targets 'Yes' than with targets 'No'. \n",
    "\n",
    "This is also something I noticed when annotating samples myself: The rationales are quite good when they are positive statements. However, they have very low quality when they need to be negative statements. I also noticed that most rationales would actually be valid negative statements (and therefore have high quality) if on part of the rationale was logically flipped or negated. However, this is a personal observation and thus not reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f3a7f",
   "metadata": {},
   "source": [
    "### Now an aggregation by correct target, whether the correct target was shown and whether the model made the correct prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "id": "d9525f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">annotation</th>\n",
       "      <th colspan=\"3\" halign=\"left\">normalized_annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th>corr_target_shown</th>\n",
       "      <th>correct_pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Middle</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.653280</td>\n",
       "      <td>21</td>\n",
       "      <td>2.501821</td>\n",
       "      <td>1.753493</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <td>2.238095</td>\n",
       "      <td>1.513432</td>\n",
       "      <td>21</td>\n",
       "      <td>2.196586</td>\n",
       "      <td>1.260922</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">No</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>2.611111</td>\n",
       "      <td>1.517098</td>\n",
       "      <td>36</td>\n",
       "      <td>2.743053</td>\n",
       "      <td>1.394258</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th>False</th>\n",
       "      <td>1.880952</td>\n",
       "      <td>1.253335</td>\n",
       "      <td>42</td>\n",
       "      <td>2.050856</td>\n",
       "      <td>1.297646</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2.479167</td>\n",
       "      <td>1.383637</td>\n",
       "      <td>48</td>\n",
       "      <td>2.796745</td>\n",
       "      <td>1.453447</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Yes</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>2.033333</td>\n",
       "      <td>1.299425</td>\n",
       "      <td>30</td>\n",
       "      <td>1.984469</td>\n",
       "      <td>1.096770</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th>False</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.924211</td>\n",
       "      <td>33</td>\n",
       "      <td>1.885452</td>\n",
       "      <td>0.850959</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3.797101</td>\n",
       "      <td>1.356680</td>\n",
       "      <td>69</td>\n",
       "      <td>3.895970</td>\n",
       "      <td>1.312866</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      annotation                  \\\n",
       "                                            mean       std count   \n",
       "target corr_target_shown correct_pred                              \n",
       "Middle False             False          2.333333  1.653280    21   \n",
       "       True              False          2.238095  1.513432    21   \n",
       "No     False             False          2.611111  1.517098    36   \n",
       "       True              False          1.880952  1.253335    42   \n",
       "                         True           2.479167  1.383637    48   \n",
       "Yes    False             False          2.033333  1.299425    30   \n",
       "       True              False          1.666667  0.924211    33   \n",
       "                         True           3.797101  1.356680    69   \n",
       "\n",
       "                                      normalized_annotation                  \n",
       "                                                       mean       std count  \n",
       "target corr_target_shown correct_pred                                        \n",
       "Middle False             False                     2.501821  1.753493    21  \n",
       "       True              False                     2.196586  1.260922    21  \n",
       "No     False             False                     2.743053  1.394258    36  \n",
       "       True              False                     2.050856  1.297646    42  \n",
       "                         True                      2.796745  1.453447    48  \n",
       "Yes    False             False                     1.984469  1.096770    30  \n",
       "       True              False                     1.885452  0.850959    33  \n",
       "                         True                      3.895970  1.312866    69  "
      ]
     },
     "execution_count": 972,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['target', 'corr_target_shown', 'correct_pred']).agg({'annotation': ['mean', 'std', 'count'], 'normalized_annotation': ['mean', 'std', 'count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35af858",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "First, we notice that we have no annotations for correctly predicted targets 'in the middle'. This is unfortunate, since this label would give valuable insights into what the model would do if it correctly identified non-polar answers.\n",
    "\n",
    "An interesting result is that if the correct target is 'Yes' and we show this to the annotator, the rationale quality seems to be much better perceived if the model also predicted 'Yes' instead of a different label. This indicates that the rationale quality suffers under wrong predictions. However, it is not possible to draw conclusions about the model faithfulness because for this we would need to consider the model prediction instead of a correct/incorrect prediction. As the number of annotations per group is already very small, we cannot make such a split. Further, we discussed earlier that we suspect that annotators did not rate faithfulness in a large portion of shown samples.\n",
    "\n",
    "Another interesting observation is that for a target 'No', showing the incorrect prediction instead of the true label results in a roughly equaly perceived rationale quality as when showing the true label 'No' under a correct prediction. This could result from the following situation:\n",
    "- the model is better at generating positive (or neutral to positive) rationales\n",
    "- the model generates decent negative rationales if the target 'No' is correctly predicted\n",
    "- the model is highly faithful towards it's prediction\n",
    "- the annotators rate the situation in which the target 'No' is correctly predicted highly as the prediction as well as the rationale make sense in case of the given sample\n",
    "- the annotators rate the situation in which a wrong prediction is shown instead of the true target 'No' highly as positive rationales are generally of high quality\n",
    "\n",
    "However, the low number of annotations and the simplicity of the survey setup again prohibit us from drawing any definite conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd16816",
   "metadata": {},
   "source": [
    "### We now investigate average ratings by shown vs. true target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "73ac9e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pivot_mean = pd.pivot_table(data, values='normalized_annotation', index='target', columns='shown_target', aggfunc=np.mean)\n",
    "pivot_std = pd.pivot_table(data, values='normalized_annotation', index='target', columns='shown_target', aggfunc=np.std)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(pivot_mean.to_numpy())\n",
    "ax.set_xticks(np.arange(len(pivot_mean.columns)))\n",
    "ax.set_yticks(np.arange(len(pivot_mean.index)))\n",
    "ax.set_xticklabels(pivot_mean.columns)\n",
    "ax.set_yticklabels(pivot_mean.index)\n",
    "ax.set_ylabel(\"True Target\")\n",
    "ax.set_xlabel(\"Shown Target\")\n",
    "ax.set_title(\"Mean (std) of annotations by shown vs. true target\")\n",
    "plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "for i in range(len(pivot_mean.index)):\n",
    "    for j in range(len(pivot_mean.columns)):\n",
    "        text = ax.text(j, i, str(round(pivot_mean.to_numpy()[i, j], 2))+\" (\"+str(round(pivot_std.to_numpy()[i, j], 2))+\")\",\n",
    "                       ha=\"center\", va=\"center\", color=\"w\" if round(pivot_mean.to_numpy()[i, j], 2) < 3.5 else \"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a025c4",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "As expected from our previous observations, if we show the target 'Yes' and it is also the true target, the quality of the rationale is fairly high. This again supports that the model is good at generating positive rationales as the shown target could not only correspond to a correct but also to a wrong prediction. \n",
    "\n",
    "If the model predicts 'in the middle' instead of the true target 'No' and we show the prediction to the annotator, the rating is extremely high (for our results). This could either result from the model being faithful (which we can't properly judge due to the annotators apparently disregarding the survey instructions) or again because of the model being better at generating positive rationales. \n",
    "\n",
    "Also high ratings were given to showing the wrong prediction 'Yes' instead of the true target. Again, the same reasoning can be applied of this either being due to high faithfulness in the rationales or because of the model having an easier time to generate positive rationales. \n",
    "\n",
    "Further, if a wrong prediction 'No' is shown instead of the true target 'Yes', the perceived quality of the rationales is extremely low. This could either be because wrong predictions 'No' do not work well with indirect answers that actually mean 'Yes' (and we suspect annotators do not solely evaluate faithfulness but also predictions) or because the model is mostly unable to produce proper negative rationales in this case.\n",
    "\n",
    "On the contrary, if we show the wrong model prediction 'Yes' for a sample that actually has target 'No', the perceived quality of the rationales is roughly the same as when showing the true target no. However, we cannot draw the conclusion that this is due to the model being better at generating positive rationales as we have no way of evaluating how well the shown target 'Yes' is compatible with samples with true targets 'No' and in this graphic, the shown target 'No' can either be a correct prediction or the true target under an incorrect prediction and thus possibly a positive rationale. Further splitting the data would again result in too few annotations for conclusions.\n",
    "\n",
    "The top left quadrant corresponds to the true target 'in the middle' being shown instead of a wrong prediction as we have seen before that there are no instances with correct predictions for 'in the middle'.\n",
    "\n",
    "From the top row we can further observe that the model might indeed be better at generating positive rationales than negative ones as if the correct target is 'in the middle', showing rationales with the wrongly predicted target 'Yes' leads to a higher perceived rationale quality than showing rationales with the wrongly predicted label 'No'. However, it is not clear whether instances with true target 'in the middle' are more coherent when being paired with an incorrect target 'No' or incorrect target 'Yes'. This would require a separate human evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c276f9",
   "metadata": {},
   "source": [
    "### We now look at annotations by true target vs. prediction if the correct target is shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "8e601f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARcAAAEWCAYAAABMj9NxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hU1dbA4d+a9JBQQgi9I4j0jqB0aYooImJBURQVy722i+1+tmtXFK+9K6JiwYYIgoCAhd5Beq9JIBAggZT1/XEOMTCTBjlJ4K73eXiYmbP32WtOZtbZe58yoqoYY0xh8xV3AMaYM5MlF2OMJyy5GGM8YcnFGOMJSy7GGE9YcjHGeMKSy/8QEQkTkZUiUqkQ1tVFRLZlez5XRBqdwvouFZGtInJQRFqcanwliYicLyKrizuOombJxSMisklEjopI7AmvLxYRFZFaxRDWcGCmqu7KrdCJiSOfXgAeP+nInPq3q2qUqi7KIS4RkQ0isvIU2imQk9kW7t+33rHnqjpLVRsUfnQlmyUXb20Erjz2RESaABHFFw43A2M8Wvf3QFcRqXyS9WsCK/Io0wmIA+qISJuTbMcUEUsu3hoDXJvt+XXAx9kLuEOVF0Rki4jsFpE3RSTCXVZORCaISLyI7HMfV8tWd4aIPCEiv4lIsoj8fGJPKVvZGkBdYE621/q6w6RkEdkuIveKSCngJ6CKO0Q5KCJVRCRCRD5041gJHPflVtVUYAHQM4f2fSLysIhsFpE9IvKxiJRx3/9BIAhYIiLrc9me1wHfARPdx9nXn+O2EJFabm/iOnc7J4jIQyf8DV4WkR3uv5fd13LaFm1F5A8RSRKRnSLyqoiEuuua6a52iVv+igBDyIZuvEkiskJELs627EMReU1EfnTfxxwRqesuExF5yd1++0VkqYg0zmV7FS9VtX8e/AM2AT2A1UBDnC/PVpw9tAK13HIv4+z1Y4Bo4AfgaXdZeeAyINJd9iXwbbY2ZgDrgfo4PaIZwDM5xHMhsOKE13YC57uPywEt3cddgG0nlH0GmOXGWR1YHqDMK8CoHNq/AVgH1AGigPHAmGzLFaiXy/aMBA4Afd1tkgCE5mdbALXc9b/jLmsGHAEaussfB/7E6RVVAH4HnshlW7QC2gPB7rpXAf/M6b1kXwcQ4m6HB4FQoBuQDDRwl38I7AXauusfC3zuLuuFk8DLAoLzuapc3J/1nP5Zz8V7x3ovFwB/AduPLRARAW4C7lLVvaqaDDwFDAZQ1URV/VpVD7vLngQ6n7D+D1R1jaqmAF8AzXOIoyzOhzi7NOAcESmtqvtUdWEu72MQ8KQb51acRHKiZLedQK7GSTwbVPUg8AAwWESCc2kzuwE4CeFnYALOF+/CE8rktS0eU9UUVV0CLMFJMsdie1xV96hqPPAYMCSnQFR1gar+qarpqroJeAv/v0tO2uMk12dU9aiqTnPfz5XZyoxX1bmqmo6TXI69jzScnczZgKjqKlXdmc92i5wlF++NAa4ChnLCkAhnLxkJLHC7yEnAJPd1RCRSRN5yhxIHgJlAWREJyraO7JOzh3E+uIHsw/lgZncZTk9gs4j8KiLn5vI+quD0vI7ZHKBMNJCUS/3sdTbjJIiKubSZ3XXAF+4X+ghOz+e6E8rktS1yWh4otio5BSIi9d0h6i737/IUEHA4GkAVYKuqZp7QXtW84nQT0avAa8BuEXlbRErns90iZ8nFY6q6GWdity/OFyK7BCAFaKSqZd1/ZVT12If+HqAB0E5VS+NMaILTJS6opTgToVk9BVWdp6r9cYYD3+Ls7cHp1p9oJ85w6JgaAco0xOkRBLIDZ0iYvX46sDuvwN15pm7ANe4XehcwEOib0xxTAQWKbYf7ONC2eAOnF3qW+3d5kPz/TXYA1UUk+3evBtl6tLlR1VdUtRXQCGcIeF8+2y1yllyKxjCgm6oeyv6iu/d6B3hJROIARKSqiPRyi0TjJJ8kEYkBHjnZAFR1G7AWZyyPiISKyNUiUkZV03DmMzLc4ruB8iJSJtsqvgAecCeZqwF3ZF+/iIThzEVMySGEz4C7RKS2iETh7O3HuV3/vAwB1uAk2ubuv/rANo4fTpysz4CHRaSCm6z+D/jEXRZoW0TjbK+DInI2cOsJ69uNM7cUyBzgEPAvEQkRkS5AP+DzvIIUkTYi0k5EQtx1pPL336zEseRSBFR1varOz2HxSJwJvj/dLvZUnC8ROJO9ETg9nD9xhkyn4i2On0sYAmxy270FuMaN9y+cL9wGd7hWBWce4lgv7Gf8D2lfDMxQ1R0E9r5bZ6a7jlROSFC5uA54XVV3Zf8HvIn/0Ohk/AeYj9O7WwYsdF/LaVvcizPUTcbZOYw7YX2PAh+55QdlX6CqR3G2VR+cv+vrwLVuO3kp7ba3D+dvkYhzflCJJO4stPkf4PYuFgHdC3siUETmAMNUdXlhrtecviy5GGM8YcMiY4wnLLkYYzxhycUY44n8nh15WoqNjdVatWoVdxgl1pqFG4o7hBLvSPXI4g6hREtP3EfGwUMBz/E5o5NLrVq1mD8/pyPApmdoYZwicmZb/VDL4g6hRNv15Ogcl9mwyBjjCUsuxhhPWHIxxnjCkosxxhOWXIwxnrDkYozxhCUXY4wnLLkYYzxhycUY4wlLLsYYT1hyMcZ4wpKLMcYTllyMMZ6w5GKM8YQlF2OMJyy5GGM8YcnFGOMJSy7GGE9YcjHGeMKSizHGE5ZcjDGesORijPGEJRdjjCcsuRhjPGHJxRjjCUsuxhhPWHIxxnjCkosxxhOWXIwxnrDkYozxhCUXY4wngos7gP8FKSkp9O7dm2nTphEUFFRo6122bBkvvvgiH374YaGtMy93v30z7fu2ICn+AMNb/CtgmcvvvohuV3YEICg4iOpnV2VQleEk7zvkV/a5yQ/z6MAXOZycQuuezbh11LX4fD4mfTCdcc9/71c+qmwp7nnnZirXqcjR1KOMGv4Wm1ZsA6BUmUjufms4tRpVQxVevOktVs1Zy03PXM28SYtZPGNFIW4JR+VS0bzUtS8VIkqRqcqnfy3hg+UL/cpFh4TycrcLqRJVmmDx8fbSeXy5ZjkApUPDeLZTL+rHxILCfb9OYuGeHX7ruKFxK5KOpDJ+7Qr61q7PXa06Uq9ceS7+ZgzLEnb7lQ8LCuKLflcSGhREsPiYuHENLy34LWv50EYtuLZRSzIyM5m2dQNPz/mVBuViualpG+799adT3jaWXIrA+++/z4ABAwo1sQA0adKEbdu2sWXLFmrUqFGo687JlI9/5fvXJ/OvD0bkWObLURP4ctQEANpf2JIBd/YNmFja9mnBhqWbOZycgs8n3D76eu7v+xQJ2xL57x9P8seEBWxZtf24OleO7M/6JZt57PJRVG9QhdtHX8/I3k8CMGLUdcybvIQnBr9McEgQYZFhAHz3+mTueuMmT5JLRmYm//ljOssT91AqJIQJl17L7G2bWZuUeFy5axu1YO2+RIZN/oaY8AimDxrGt+tWkpaZySMduvHr1o3cOvV7Qnw+IoJD/NoJEmFQgyZcOP4jANbsS+DmKd/y1Pk9c4ztSEYGV04Yx+H0NILFx1f9r2TG1g0s2rOTcytX54KaZ9H7qw85mplB+fBIAFbvS6ByqWiqlIpmx6HkU9o2Nixybdq0iYYNG3LTTTfRqFEjevbsSUpKCgDvvPMObdq0oVmzZlx22WUcPnwYgKFDh3LnnXfSoUMH6tSpw1dffRVw3WPHjqV///4AzJgxgy5dujBw4EDOPvtsrr76alQVgMcff5w2bdrQuHFjhg8fnvV6ly5dGDlyJG3btqV+/frMmjUra939+vXj888/92y7nGjZ7L9I3ncw3+W7XNGB6eN+D7is25Ud+f2H+QA0aFOPHet3sWvjHtLTMvj1iz/o0K+1X50aDauxaJqzx9+6egcVa1agbFwZIqMjaHLe2Uz6YDoA6WkZHNrv/J32bEmgdPkoylUsU6D3mh97Ug6xPHEPAIfS0liXlEjFUlF+5RSICgkFoFRIKElHUknPzCQqJJR2larx+eplAKRlZnLg6BG/+h2q1GR5wm4y3M/EuqS9bNi/L8/4DqenARDs8xHiC8KtzjXnNOf1JXM4mpkBQGLq4aw6U7eso1+9hvncAjmz5JLN2rVrue2221ixYgVly5bl66+/BmDAgAHMmzePJUuW0LBhQ957772sOjt37mT27NlMmDCB+++/32+dR48eZcOGDdSqVSvrtUWLFvHyyy+zcuVKNmzYwG+/OV3V22+/nXnz5rF8+XJSUlKYMGFCVp309HTmzp3Lyy+/zGOPPZb1euvWrY9LNiVJWEQorXs2Y/Y3cwIub3RufdYu3AhAbNVyxG/7e28fvz2R8lXK+dXZsGwz513SBoAGretSsWYsFarGUKlOHEkJB7j33Vt4fe7T3PXmTYS7PReAtYs20ahDg8J8e36qRZWmUWxFFu/Z6bfsoxULqVeuPPOuuZXJA4fy2O/TUKBG6bIkpqbwQuc+TBxwLc926hWw59K6UlWWJ+wqcEw+ESYOuI6F197GrG2bWBzvxFa7TAxtK1Xj20uuZtxFg2laoVJWnWXxu2lbqWqB2/Jr+5TXUERERPJZbriIzBeR+fHx8QVqo3bt2jRv3hyAVq1asWnTJgCWL1/O+eefT5MmTRg7diwrVvzdvb7kkkvw+Xycc8457N7tP+5NSEigbNmyx73Wtm1bqlWrhs/no3nz5lntTJ8+nXbt2tGkSROmTZt2XDsDBgzwiwsgLi6OHTv8x+clQfuLWrLyj9UBh0QA0TFRpBxMdZ4E+PMe28tmN+6574kqV4o35j1N/9t6sW7xJjIyMggKCuKsFrWZ8NYURrR9gNRDR7jiXxdn1UuK30/5yv7JqrBEBofw5gX9efz3aRxMO+q3vHO12qxI3EObT96gz9cf8XjH7kSFhBIkQuPYinyycjF9x3/M4bQ0RjRv61c/LrIUiakpBY4rU5W+4z+i/dg3aR5XmfrlYgEI9gllwsK45NuxPDVnBq9375dVJyHlEBUj/XtfBXVazLmIiKg7RhCRy4CjwFFVnXxiWVV9G3gboHXr1gE+njkLC/t7TxcUFJQ1LBo6dCjffvstzZo148MPP2TGjBkB62iAb0NERASpqam5tpOenk5qaiojRoxg/vz5VK9enUcfffS4esfqHCt/TGpqKhEREQV5m0Wmy6Cch0QAGekZiAiqSsK2vVSoVj5rWYWq5dm707/bfzg5hRdveivr+cdrXmHXxnjCIkOJ37aXv+atB2DW+DlccV//rHKhYaEcSfH/0heGYPHx5gX9+XbdKiZtWhuwzOUNGvP6YqcHt/lAEluT91O3bAw7Diaz81ByVo9i4sbVjGjezq9+ano6YacwZ3fg6BH+2LGVLtVrs2ZfAjsPHWTSRifWJfG7yARiwiPYm5pCWFAwqRnpua8wH06Lnku2xHIPcDtQF3hURPrlWrGQJCcnU7lyZdLS0hg7dmyB6pYrV46MjAy/BHOiY8tjY2M5ePBgjvM3J1qzZg2NGzcuUExFIbJ0BE3Ob8gf3y/Iscy2NTupXCcOgNXz11O1XiUq1apAcEgQnQedyx8T/OuWKhNJcIjzJetzQzeWzV7F4eQU9u3eT/y2RKrVrwxAi26N2bJqW1a9avUrsWnF1sJ8i1me69ybdUmJvLtsfo5lth9MpmPVmgDERkRSp2wMWw7sJz7lEDsPJlOnjNOr6li1Jmv3JfrVX5eUSK3SBet5xYRHUDrU2SmFBQVzXtWarHMnmn/etJYOVZyDALXLlCPE52Ov2zOqUzaG1XsTCtRWICW65yIiZYBkVc0UkUpAO1XtKiKPAPHARBGJVNXDua/p1DzxxBO0a9eOmjVr0qRJE5KTCzaL3rNnT2bPnk2PHj1yLFO2bFluuukmmjRpQq1atWjTpk2+1j19+nQuvPDCAsVzKh4YcwdNOzWkTGw0Yze8ypjHv2LShzO48Cbnvf34zlQAOvZvw8KpS0k97D85eczcnxbRtNM57Fi/m8yMTF7954c89eMD+Hw+Jn80g80rneSQfd01zq7Kv96/lczMTDav2s6o4W9nre+1uz7k/o9uJzg0mF0bd/PCjU4PJyg4iCp1K7FmwYZC3x6tK1blsvqNWJUYz8QB1wHw/LyZTN+6kasbNgNg7KolvLLwd17s0pfJA4ciwDNzZrLviPNlfuT3Xxjd7SJCfEFsSU7i3hn+h4FnbN3IS137Zj3vVessHuvQnZiICD7ofRkrE/dw7U9fERdZiuc69WbopK+Ji4xiVJc++MSHT2DChtVM2+Jsgy9WL+P5zn34eeBQ0jIzuSdbm+dWqZ5V7lRIoK58SSAiNXGGN08AvwExwLvAbqAycIWqporIFcBCVfXrj7Zu3Vrnz895b1JUFi1axKhRoxgzZkyhrvfIkSN07tyZ2bNnExxc8P1Ez9ArCzWegoqpVJZ/vT+C+/s+5Wk7Hfu3pl6L2nz06JcFrrv61ZYeRHRy3rrgEp6eM4NNB5I8ayPUF8S4foMZ+P2nWUemcrPrydEc2bwt4HxoiRwWiUhZVd0MTANGAu1VNRFYAnQH7nETy/XAg0D+j40WgxYtWtC1a1cyMjIKdb1btmzhmWeeOanEUhLs3ZXExPenERnt7ZyRLziIr1760dM2isKzc38lrhAmWnNTJSqaZ+fOzFdiyUuJ67mISF2chPGJqk4XkbuAXsCjwGHgUuByYJL7+mBVDXh2VEnpuZRUxd1zOR2UpJ5LSZRbz6XE7fJUdb2IbAb6i0i6qr7kHoZ+CPgP8BTwB3AEeE1VNxZjuMaYHJSY5HLsPBb3yNBa4Bago4jcqaqj3MUPA8+r6s/FF6kxJj9K0pyLqKqKyFBgBHAPsA64UUTOV9VROD2WO0QkvBjjNMbkQ7EnFxHpLiLnuYebg4DWwOeqOl9VrwT2AM+KSGdVfQoYrqq5nzRijCl2xZ5cgBrATBE5V1UzgMVAIxGpAaCqDwBlgT7uOS15X61ljCl2xTbnIiI+Vc1U1Q/cRDJBRLoDPwAdgH4i8idQAVgO/Nfrk+WMMYWn2JKLqmYCiMgIIBLnHJZfgM7Ac8AQ4BkgHLhFVbfnsCpjTAlU5MlFRKoeSxQi0gz4B3CBqm4RkRuAmUAnVX1IRMrhTPTuLeo4jTGnpkjnXESkKjBMRI6dZrgTmOcmliBVfR/4DlgqIm1UdZ8lFmNOT0WWXESktNtjGQXUF5FhQCJQW0SecidzAaYA7wMHiio2Y0zhK5JhkYj0Ap4SkZGqOlVEWgJdgS1AX+APEakI7AfOBy5SVf87LxljThtFNedSH2gEjHSHP++KSApwjbu8NTAA58jQtZZYjDn9FVVy+QyoA2wFbhGRUFUdKyI+YDAQp6qfFFEsxpgi4FlyEZGmAKq6FNiLc2vKc4A3cE7hz1DVMSISBrQTkQmqut+reIwxRcuT5CIi5XHOtN0mIncDm3Guah4NCDAWpwcT4g6RSquqTeAacwbx5GiRe2OnHkA1oCnQG/gY534sFVT1c+Ab4CoRKWWJxZgzj2eHolV1GnABcB3wOvAr0BbnGqFQ4CvgJlUN/LsTxpjTmqcTuqr6i4jcCswAzlXVt0SktqoexZmDMcacoTw/WqSqE90bPc0TkY7H7hyX/beIjDFnniI5FO0mmBBgqoi0dl6yxGLMmazITv9X1e9wLkjMtMRizJmvSC9cVNUS/RMgxpjCUxLuRGeMOQNZcjHGeMKSizHGE5ZcjDGesORijPGEJRdjjCcsuRhjPCFn8vls4XWrarWnbi3uMEqsjN0RxR1CiVfvn38Wdwgl2hz9hQO6VwIts56LMcYTllyMMZ6w5GKM8YQlF2OMJyy5GGM8YcnFGOMJSy7GGE9YcjHGeMKSizHGE3kmFxH5JT+vGWNMdjneoFtEwoFIIFZEyuH8UiJAaaBKEcRmjDmN5Xb3/5uBf+IkkoXZXj8AvOZlUMaY01+OyUVVRwOjReQOVf1vEcZkjDkD5GdC930ReVhE3gYQkbNE5CKP4zLGnObylVxwfnq1g/t8G/AfzyIyxpwR8pNc6qrqc0AagKqm8PfkrjHGBJSf5HJURCIABRCRusART6Myxpz28vNb0Y8Ak4DqIjIW6AgM9TIoY8zpL8/koqpTRGQh0B5nOPQPVU3wPDJjzGktz+QiIi3dhzvd/2uISBlgs6qmexaZMea0lp9h0etAS2ApTs+lsfu4vIjcoqo/exifMeY0lZ8J3U1AC1VtraqtgBbAcqAH8JyHsRljTmP5SS5nq+qKY09UdSVOstngXVjGmNNdfoZFa0TkDeBz9/kV7mthuOe+GGPMifLTc7kOWIdzEeNdwAacQ9FpQFfPIjPGnNZy7bmISBDwg6r2AF4MUOSgJ1EZY057ufZcVDUDOOweejbGmHzLz5xLKrBMRKYAh469qKp3ehaVMea0l5/k8qP7zxhj8i0/p/9/VBSBGGPOLPk5/f8s4GngHCD82OuqWsfDuIwxp7n8DIs+wLky+iWcQ8/Xc4bczyXUF8Rn3a4lNCiYYPExaesqRq+YGbDsv1v0pEvleqRkpDFy7g+s2LcLgKfbXES3KmeReOQQfSe9nWNbQ+u3JeloCt9uWkafag25s3En6paOZcCU91m+b2eO9XwifHvBMHalJDN81jgAGpatyBOt+xDqCyZDM3lkwSSW7t1B/TIVGNagPSPn/nAKWyVnlaOiebFnbypEliJTlc+WL+XDJYv8ykWHhvJSr75UiYomyOfjnYXz+WrVigBrhLGXXs7NP37HwaNHebZ7L7rVrkNiymF6j829w9w0riLjB13FHZMm8NO6tQDMGnojB48eJVOV9MxM+o8bC8CD53Vm+qYN/LFt6ylugcDuee9W2l3YiqQ9+xne9J6cY+58DiNeup6gkCAOJCRzT9dHqFa/Cg9/fldWmUp14vjokXF8M3qiX/1L/9GX5L0HmTpmJp0GtmfII4Oo0bAqd7R7gDULAp/T2rpXc0a8fD2+IB8/vfcL4579FiDH+rUa1+Dyu/vx/A2nfpvs/JznEqGqvwCiqptV9VGg2ym3XAIczcxgyIxP6Df5HfpNfofzK9elefmqfuU6V65LregYuk98nYfnT+SxVn2ylo3ftJQbZn6WaztBIgys3YwfNi8HYM3+PYz47UvmxW/JM8ahZ7Vl3YHjL0If2aw7ryyfxcU/v8vLy39lZLPu7nrjqRRRmsqRpfNc78lIz8zkyVm/csEnHzLgi0+5tmlz6sXE+JUb0rQ5axMT6fvZGK4c/wUPnd+ZEJ//R61rrdqsSojn4NGjAHy9ajlDv/s6zzh8Iozs2ImZWzb5Lbtq/Jdc+NmYrMQC8NGShdzaum0B3mnB/PzhDB7s82SuZUqVieTO127i3/2f5aYmd/PEIOfMjm1rdnBLy/u4peV9jGg9kiOHj/LbN3P96vuCfPS+vhvTPp0NwKblW3nsshdYNnNVjm36fD7ueHUYD/Z9khsb3UXXwR2p0bBarvU3Ld9CbLUYKlSPLdA2CNh+TgtEpL37MFVEfMBaEbldRC4F4k655RLicLpzknGwz0eIz4eq+pXpUbUB32xaBsDixO2UDgmnQngUAPPit5B0JCXXNs6Nq82KfbvIcNe9PjmRjcl784ytUkQ0XarU44sNi497XVWJCgkDIDoknN0pyVnLpu1Yw0U1GuW57pMRf/gQK+L3AHAoLY11+/ZSqVS0XzkFSoWGAhAZEkJSairpmZl+5fo3aMiUDeuyns/dsZ2k1NQ847iuWQsmrV9L4uHD+Yp7e3IyZcMjiI2MzFf5glo2axXJe3M/5avbVecx+5s5xG91dhRJ8Qf8yrTo3pid63exZ4v/HU1adGvMuoUbycxwtuOWv7azbc2OXNts0LYeO9btYtfGPaSnpTNj3G906N86z/p/TlhA18EdAi4riNx6Lq+7//8T5/eL7gRaAUNwzto9I/hE+L7njczpfzezd21kyV7/DV4xIpqdh//+MOxKOUDFCP8vVU5axVbLdeiTk4db9OTZJb/4Jbz/LPqZ+5t1Z1a/O7m/WXdeWDo9a9myfTtpE1u9wG0VVNXo0pxTIY7Fu/3f18dLFlEvJoY5w25m0lXX8fjM6finbGhduSrL9+wuULsVS0XRq249xi5b4rdMFT6+5DK+H3wNVzZqctyyFXt207qyf6+0qFSrX4XocqV4YdqjvDbvWXoM6eRXpsvgjkz//LeA9Rt1PJs1C9cXqM3YqjHEb0vMep6wbS+xVcvnWW/N/PU0Pq9hgdoKJD9Hi+a5Dw/izLcUCxERDdCtOPF1ERkODAcIjs373L9MVS7++V2iQ8J4o+PlnFWmAmv3xx/fRoB6GvDrEliFiCi/oU1eulauR+KRQ6zYt4t2FWoet+yqeq14cvEUJm/7i77VG/J0m4u47ldnGJCYeoi4AiS+kxEZEsIbF17MEzOnZw1psutUsxYr4+O5avyX1CxTljGXDGTejo/9ypYJD+dQWsEuT/u/Tl145rdZZAboYQ786jP2HDpE+YgIxlwykPX79jJ3x3YAElMOU7FUVIHaKkxBwUGc1bIO/+rxOKERobzy+5Os+nMt29c6yTk4JJhz+7XmvQc+DVg/pnI5tqzaVqA2JcAHN1DP/ERJe/ZTvor/cLegcksudUTk+5wWqurFp9x6PmVPIO7PmhwFglT1J1XV7MtV9W3gbYDwulXznQGS044wJ34znSrV9Usuu1KSj5vHqBRRmj0p+b/yITUjnbCg/Myd/61VbHW6V6lP58r1CPMFExUSxovt+nPPnO8YUKspTyxybqMzcesqnmrz9y+9hAUFk5rh3T28gn0+3uh7Md+tXsXk9esClhnYsDFvLnDmDTbvT2Lrgf3ULRfDkt27jiuXkZmJQAHSNDSJq8R/e18IQLnwCLrUqkN6pjJlwzr2HHLO8UxMSWHyhnU0q1g5K7l4vV3yEr8tkf0JB0g9fITUw0dYOmsVdZvVzEoubfo0Z93CjSTt2R+w/tGUo4SGhxawzb1UqPZ3TyW2WgyJO/IejoeEh3I0xX+nUVC5feLjCXw9UbERkRHATTgn9V0qIp1V9f5APZr8iAmLJC0zg+S0I4QFBdOhYm3eXvW7X7lftvqctQ8AABmfSURBVK9hyFmtmbBlBc3LVyU5LZX41Pwnl/UHEqgZVbA9wQvLpvPCMme4065CTYad3Z575nwHwO7Ug7SrUJM58Zs5N64Wm7LN39SOLs+a/XsK1FZBPNu9J+v2JvLeogU5ltmRfIAO1Wswb8d2YiMiqVOuHFv2+39pNiTtpUaZsmzen5Tv9jt99G7W4+d79GLapg1M2bCOiOBgfCIcSksjIjiY82vU4pW5f2SVrV2uHD+uW5PvdgrbH9/N4/b/DsMX5CMkNJiz29Zj/EsTspZ3HXwe0z+fnWP9Lau2UaVepQK1uXreOqqeVZlKteJI2L6XLld05OmrR+dZr1r9ymxakffBhrzkllySVfXXU27hFIhIDSBRVQ+JSBxwOXCVqq4SkReBuSKy/WR/EbJCeBTPt7sYnwg+ESZuWcX0nc7e+Mq6zt09P1u/kBk719Glcj2mXXgbKelpxx3qfan9pbSLq0G5sEhm97uT0ctn8uXG4ydgf925nhfa9c96fkHVBjzSshcxYZG82+kKVu3bzfUzPyMuPIqn2lzEjbM+JzcPzfuRf7foSZDPx5GMdB6a//cJ1O3jajJjZ+AexalqXbkqAxo24q+EeH68cggAz/8+mxmbN3JV46YAfLp8Kf+d9ycvXNCbn666FhHh2d9msS/Vf9J7+saNtK9WPSu5jO51Ie2rVaNceAS/3zCcl//8nS9WLj9u3TmJjSzFWxc6nekgn4/vV//FzM2bAKe3VbNMWZad0HMqLA+O/QdNuzSiTGw0n255k48f/YJJ70/jopsvAGDCW1PY8td25k1ezNtLXiQzM5Of3vuFTSucQ+NhEaG0uqApL9+S86kMc39axMiP78h63vGSttz2yg2UqVCa/0x4gPWLN/FAnycpX7kcd79zCw9d9DSZGZm8esd7PD3pIXxBPiZ/MJ3NK7flWh+gedfGzPlxYcA4CkJy2umLyHhVHXDKLZwkEakIPAhsBd5U1YMi8iVwv6qud8v0Azqo6gOB1hFet6pWe+rWIos5N693HMizS35h88F9nrUR6gvi025DuOKXj7KOTOUmY3eEZ7HkR4XIUozq2Ych337laTs969SjcVwco/7075Xmpd4///QgopPzyNf38e7IMWxf502SBAgJDebFGY/xz/P/nXVkKjdz9BcO6N6A573leLSoOBOLKx6YB1QBrhcRwbmXzOcicqzHVQvnJ0+CiifE/Ht+6TTPJ1orR5bm+SXT85VYSoL4w4f4fMVSokILNpdQUME+H+8szHkYd7p474GxxFQu52kbcTViefeBsflKLHnJsedSXNzLDXyqutpNKBcBfYDFqvq2e1e8Zjg3CW8HXO3eetNPSeq5lETF3XM5HZSknktJlFvPpWCHMDwmIuWB1UCCiDwGZOAc+SkD1BORm1X1VhFpB0QAz6rqxuKL2BiTk/xcuCjA1UAdVX3cnWStpKr+5yifIlVNFJEewFScIVszYBzOOTZHgSZuPB+oqv2krDElWH6uLXodOBe40n2eDJz6VU05UNVpQC9gBHA7cDcwA6gBdHFfC8+hujGmhMjPsKidqrYUkUUAqrpPRDydgXN/QvZenN9Haq+qH7kn9IUAkaoa+EwjY0yJkZ/kkuYejTl2hmwF4NSnkvOgqj+KSCbwp4icq6qJeVYyxpQY+UkurwDfAHEi8iQwEHjY06hcqvqT20uaKiKtVNXzpGaMKRz5uXBxrIgsALrjXMN3iarmfBOJQqaq34nIL5ZYjDm95OdoUQ3gMPBD9tdU9dQvPsgnVbXfRzLmNJPfu/8rTq8lHKiNcy6KN3ckMsacEfIzLDrurjsi0hK42bOIjDFnhPyc53IcVV0ItPEgFmPMGSQ/cy53Z3vqA1riXFRojDE5ys+cS/ZLedNx5mDyvkW7MeZ/Wq7JxT15LkpV7yuieIwxZ4jcflokWFUzcIZBxhhTILn1XObiJJbF7nU9XwKHji1U1fEex2aMOY3lZ84lBkjE+ZXFY+e7KGDJxRiTo9ySS5x7pGg5fyeVY0rW7euMMSVObsklCIgip98EM8aYXOSWXHaq6uNFFokx5oyS2xm6AW+6a4wx+ZFbculeZFEYY844uf1uUd4/KmuMMTko8IWLxhiTH5ZcjDGesORijPGEJRdjjCcsuRhjPGHJxRjjiRL1Q/SFLWynUveZo8UdRonlS7AbCublxx2LizuEEq1tr8M5LrOeizHGE5ZcjDGesORijPGEJRdjjCcsuRhjPGHJxRjjCUsuxhhPWHIxxnjCkosxxhOWXIwxnrDkYozxhCUXY4wnLLkYYzxhycUY4wlLLsYYT1hyMcZ4wpKLMcYTllyMMZ6w5GKM8YQlF2OMJyy5GGM8YcnFGOMJSy7GGE9YcjHGeMKSizHGE5ZcjDGesORijPGEJRdjjCcsuRhjPGHJxRjjCUsuxhhPWHIxxngiuLgDKG53P3IJ7TrVJ2nvIW6+/LWAZaKiw7n70UuoXC2GtKPpvPjot2xev4dqNcvz4LODsspVqlqOMW9M55tP//Bbx6VXnUvygcNMnbCE6NIRPPjsICpWKcvuHUk8+a9xHExO9atzyZXt6TOgFSLCT+MXZK33mpu70mdAK/bvOwTAB69OZd7stdSqF8dlQzry4iPfFMamAeCuF66kbfdGJCUe5NYezwQsExkdzr9GD6FC1XIEBfn4+u3pTPliTtZyn0945cd7Sdi1n0evfzvgOi4Z1pnkpMP88vU8ospG8sBrQ6lYPYbdW/fy9IgPOLg/xb/OjV3oPbg9Cmz6awej7vmUtCPpnHdhc665qzfVz6rIP/uNYu3SrQDUOrsyA4Z3ZdTdn576hgkgNTWTLpdu58hRJT0dLruoFI/eV96v3L6kDIbdtYcNm9MIDxPefSmOxmeH+ZVTVS64fAfjP6hM6Wgfw+7azY9TDhMXG8TSGTUCxvDdpIM88txefD4IDhJGPR7Lee0iAHKsf99jCfTpHkm38yILaUs4/ud7Lj//sIiHbhuTa5nBwzqxfvUubr3idZ7/93huva8vANs2JzJi8BuMGPwGt1/1JkdS0/ht+kq/+r4gHz37t2DaT8sAGHT9+Syau4Eb+o9m0dwNXHH9+X51ataNo8+AVtw55G1uueJ12nWqT5UaMVnLv/nkj6y2581eC8CmdXuoULE0FSqVOentcaIpX87l4SFv5lqm33Xns2XtLm7r9RwjB/2Xm/7dn+CQoKzl/Yd1Zsu63TnW9wX56HlFe6Z/uwCAQSN6sPi3NdzY6T8s/m0Ng0b08KtTvlIZ+l/fiTsvepFbezyDz+ej88UtAdi8eidPDH+f5XPWH1dn0187ia1UlgpVyuX7/RdEWJgw9auqLPqlBgunVmfy9MP8ucB/p/H0K/to3jiMxdNq8OErFbnr3wkB1zfxl8M0PSeU0tHO1/S6QaWZ+GnlXGPofn4ki36pzsKpNXj3pTiG37Mna1lO9W+/oQzP/ndfQd5qvvzPJ5flCzeTHGCvmF2NOnEsnrsBgK2bEqhYpSxlY0odV6Z52zrs3LaPPTv3+9Vv3qY26/7aSWZGJgDndjmbqT8sAmDqD4s4t2tD/zZrV2DVsm0cSU0jMyOTpQs20bHrOXm+nz9/XU2XXk3yLJdfy+esJznpcK5lVJWIqHAAwkuFkZx0mIx0573GVipD226NmPyZf2/umOYdz2Ld8q1/b5+ejZn61VwApn41l3NzeD9BwT5Cw0PwBfkIiwhl725n229dt5vtG/YErDNn6go6X9wi1/dzskSEqFLOVyotTUlLAxH/civXHKXbeU5v4uyzQtm0NY3d8el+5T4dn8zFvf/+nHU6N4KYckF+5bKLKuVD3EYPHc48rv2c6tesHsLefZns2uMfw6k4bZKLSKA/U9HYuGYXHbs7X+wGjapSsXIZYiuWPq5Ml15NmDFpacD6jZrXYO2qHVnPy5Uvxd6EgwDsTTjol6gANq3fTZOWNYkuE0FYeAhtzqtPhUp/t9lvcFveGDeCux+5hKjo8KzX16zcQeMWNU/+zZ6EHz6cRfV6FRk7/3HemHI/bz4yHlUF4OZHB/DeU9+Rmak51j+ndR3WuUMXgLKx0ezbcwCAfXsOUKZ8tF+dxF37+fqt6Xz856N8uuAJDiensHDm6jxjXbt0C43b1i3oW8y3jAylZY8tVGqykR6dI2jXMtyvTLNzwvhmovP3n7solc3b0tm2w/+L/fvcVFo19a+fl28mHuSc8zbTb8hO3n0pLl91WjQJ47e5/r2sU3FaJBcREXU/rSJysYhUz6XscBGZLyLzj6bnvsfNr3EfzCI6OpzXP7+Viwe3Y93qXVl7WYDg4CDad27AzCkrAtaPiY3Omh/Jr60bE/jiw9k8/cZ1PPnaEDau2ZXVG5jw5Vyu7/cyIwa/wd6EZIbf3TurXtK+g5Sv4P9l9FKrzmezYeV2rm79f9zW+zlGPDGQyKiwrLmadcu25Vo/Jq40+/ceLFCbUWUiaN+zMdd3eIyrW/+bsMhQul7aOs96SQkHialYeMPGEwUFCQun1mDLwlrMW3SE5X8d8Ssz8o5y7NufScseW3j1vf20aBxGcLD/vnNvUgbRUQX/il7aN4qVs2sy/v3KPPLc3nzViYsNYufuwu25nBYTutkSy23ACOCiXMq+DbwNUCaySs67ywI4fOgILz76bdbzj368i13bk7KetznvLNb9tZOkvYETyJEjaYSG/r2p9yUeIiY2ir0JB4mJjcqx3uRvFzL524UAXH97D+Ldbn/28j+NX8Djr1yd9Tw0NJgjR9JO4l2evAsGteOL16cCsHNTAru2JlKtXkXOaV2b9hc0pk3XhoSEhRAZHc59o4fw/D+On+M6kppGSFhI1vOkhGTKxZVm354DlIsrzf7EZL82m5/XgN1b97Lf3Ra//7SUc1rXZvo383ONNTQ8mKOp3m+fsmWC6NwhgsnTD/tN1paO9vH+yxUBZ0hZt+1matcI8VtHcLCQman4fCfXae90bgTr/5FGQmIGseVzH06lHlHCwwt3cHBa9FwARKQtcCPQTVU3ish5ItJGRMp63XapqHCCg50/Tp9LW7F84WYOH/p7j9SldxNmTFqWY/2tG+OpUv3vowZ//voXPfo54/4e/Vrwx4y/AtYrU84ZLlWoVIaO3RpmtRETG5VVpkO3hmxa//f8QrWasWxeH3i+wSvxO/bRvGN9wBnSVKsbx67NiXz47ASGtH2EoR0e55nbPmLJb2v9Egs4cyRVasVmPf9zynJ6DGwLQI+Bbfnj5+X+bW7fx9ktahIW7nwpm3esz9a1u/KMtWrtODat3nlS7zMv8QkZJO3PACAlJZNfZh6mQb1Qv3JJ+zM4etTZ77079gDnt4/ImrTNrkHdEDZsLlgiXLfxaNaQdOHSVI6mKeVj8v6ar9lwNOARq1NRInsu2edXjvVagARgGnC/u7wjsB14B/jxZNu6/+mBNG1VmzJlI/lk0j2MeXM6k79dyIUDnS72j1/Np0adCtz3xAAyMzLZvCGelx77uxcTFh5Cy3Z1Gf2f73NsY95va/nXfy7Lej7ug1k89OwV9L6kJXt27ufJf40DIKZCNHf9X3/+fccnAPzfC4OJLhtBRnomrz7zY9bh6mH/6EndBpVRVXbvTOKVbG03a12bObPWnOzm8DPy1Wtp2r4epWOiGDP3Mca8+BM/j/uTvtd0BGDiJ7/x6ejJ3DPqal6fMhIR4f2nfuBAAYaB86ev5N7R12Q9/+K1qTz4xvX0Gtye+O37ePLWDwCIqViafz53Jf933VusXryZ2ROX8N+f7iMjI5P1y7fx06e/A9Chd1NuffwyysRE8diHN7Nh5TYevsY54tW0Qz3mTQs8fD1VO/ekc/0/dpORAZmZcPnFUVx0gbODePMjp9d5y3VlWLX2KEPv3EOQDxrWD+XdUYHnRfp2L8WM31OoV9tJUFfduotff08hYW8GNVpu5JF7yzPsqtLHrXv8j4cY82UyISEQES589malrAnenOqnpSnrN6bRulnhJhf5+7tbcohIDVXd4j5uAgiwEhgG1AG+UNUFIvIckKCqzwVaT5nIKtq+wY1FFXau/u/Fwbw7+md2bMnfGPhkhIQE8fy7N3D3De8dNyeUE1+C/5Gt4vLvd4bx3pPfs2NTvGdthIQG8dyXd3LPgNH52j4AP86b6Fk8edm5O53r7tzNz+OqetrONxMPsmjZER4f6X9OTl7a9trK/CWpAcdTJa7nIiJxwHvABSJyH878yrGD8Leq6k633CCgO3BVsQRaQO+/MoWY2GhPk0uFymV4/5Up+f7ilCTvP/0DMRVLe5pcKlSJ4f2nfzhttk/lisHceHVpDiRnBhw2FZb0DLj7lsKfXShxyQUIAUqLyBVAB1XtLCIPAt2A3QAicj4wBBiqqnkffywBtm1OZNvmRE/b2LFlr6fJy0vbN+zJ8dyUwrJjU7ynycsLgy72/sjf5f2i8i50EkpcclHV7SIyBagB/CAizwPNgD6qmikiF6jqFBFZpqpJua/NGFNcSkRyEZFOQH9AgQ+AKkB9IBQIx0ksGSIyFLhVRBao6um5izbmf0SJSC44w53fgQtwhjvnA0uBXcDZwD9EpDLQC7jSEosxJV+JSC7uvMlq4GsAEfkcJ5EcAZKAPTi9mIGqWnjHWY0xnikRyQX+PsXf/X+xiKQCV+DEuERVPynmEI0xBVBiztA9drJctv//Ar4AEnGPEhljTh8lpucSiKquEpF1qlq0F8sYY05Ziem55MQSizGnpxKfXIwxpydLLsYYT1hyMcZ4wpKLMcYTllyMMZ6w5GKM8YQlF2OMJyy5GGM8YcnFGOMJSy7GGE9YcjHGeMKSizHGE5ZcjDGesORijPGEJRdjjCcsuRhjPGHJxRjjCUsuxhhPWHIxxnjCkosxxhOWXIwxnhD3Z4LOSCISD2wu7jiyiQUSijuIEsy2T95K2jaqqaoVAi04o5NLSSMi81W1dXHHUVLZ9snb6bSNbFhkjPGEJRdjjCcsuRStt4s7gBLOtk/eTpttZHMuxhhPWM/FGOMJSy7GGE9YcikAEVERGZPtebCIxIvIBPf5xSJyfw51D+bw+ociMtB9PENETovDjKfK3ZYvZnt+r4g8WowhlQjimC0ifbK9NkhEJhVnXCfDkkvBHAIai0iE+/wCYPuxhar6vao+UyyRnX6OAANEJLa4AylJ1JkEvQUYJSLhIlIKeBK4rXgjKzhLLgX3E3Ch+/hK4LNjC0RkqIi86j6uLSJ/iMg8EXkiWxkRkVdFZKWI/AjEBWpERHq69ReKyJciEuXdWyoW6ThHPu46cYGI1BSRX0Rkqft/jaIPr/io6nLgB2Ak8AjwCfCQ+1laJCL9AUSkkYjMFZHF7rY6qxjD9mPJpeA+BwaLSDjQFJiTQ7nRwBuq2gbYle31S4EGQBPgJqDDiRXdvfnDQA9VbQnMB+4utHdQcrwGXC0iZU54/VXgY1VtCowFXinyyIrfY8BVQB8gHJjmfpa6As+7PZpbgNGq2hxoDWwrrmADCS7uAE43qrpURGrh9Fom5lK0I3CZ+3gM8Kz7uBPwmapmADtEZFqAuu2Bc4DfRAQgFPjjlIMvYVT1gIh8DNwJpGRbdC4wwH08BniuqGMrbqp6SETGAQeBQUA/EbnXXRwO1MD5TDwkItWA8aq6tniiDcySy8n5HngB6AKUz6VcTicR5XVykQBTVPXKgod22nkZWAh8kEuZ/9WTsTLdfwJcpqqrT1i+SkTm4AzTJ4vIjaoaaGdVLGxYdHLeBx5X1WW5lPkNGOw+vjrb6zNxhlVBIlIZp5t7oj+BjiJSD0BEIkWkfiHEXeKo6l7gC2BYtpd/5/htN7uo4yphJgN3iNuNFZEW7v91gA2q+grODq9p8YXoz5LLSVDVbao6Oo9i/wBuE5F5QPY5hW+AtcAy4A3g1wDrjweGAp+JyFKcZHN2IYReUr2IcyuBY+4Ernff+xCcbfm/7AkgBFgqIsvd5wBXAMtFZDHO5+PjYoovIDv93xjjCeu5GGM8YcnFGOMJSy7GGE9YcjHGeMKSizHGE5ZcTL6JSIZ7Hcty93qnyFNYV/arwd8VkXNyKdtFRDpke36LiFx7sm2bomHJxRREiqo2V9XGwFGca1uyiEjQyaxUVW9U1ZW5FOlCtmuwVPVNVS1R53QYf5ZczMmaBdRzexXTReRTYJl75vHz7hW8S0XkZsj9avDs97ERkd7uleBL3Cuia+EksbvcXtP5IvLosetsRKS5iPzptvWNiJTLts5n3auG14jI+UW6dYxdW2QKTkSCca7WPXYDo7ZAY1XdKCLDgf2q2kZEwnAuvvwZaMHfV4NXBFbiXEaRfb0VgHeATu66YlR1r4i8CRxU1Rfcct2zVfsYuENVfxWRx3FuUfBPd1mwqrYVkb7u6z0Ke1uYnFlyMQUR4Z5qDk7P5T2c4cpcVd3ovt4TaHpsPgXn0oezyP/V4DOPrcu97ihH7q0ayqrqsUsoPgK+zFZkvPv/AqBW/t6iKSyWXExBpLj3DsniXkt3KPtLOD2JySeU60v+rgYvzOtRjrj/Z2Cf9SJncy6msE0GbhWREAARqe/e2Cg/V4P/AXQWkdpu3Rj39WQg+sTCqrof2JdtPmUIAS4ENcXDsrkpbO/iDEEWurcIiAcuwbkavBvO1eBryOFqcHfOZryI+IA9OPcp/gH4yr294x0nVLsOeNM9LL4BuN6LN2UKzq6KNsZ4woZFxhhPWHIxxnjCkosxxhOWXIwxnrDkYozxhCUXY4wnLLkYYzzx/4Ua8poL96HbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pivot_mean = pd.pivot_table(data[data['corr_target_shown'] == True], values='normalized_annotation', index='target', columns='prediction', aggfunc=np.mean)\n",
    "pivot_std = pd.pivot_table(data[data['corr_target_shown'] == True], values='normalized_annotation', index='target', columns='prediction', aggfunc=np.std)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(pivot_mean.to_numpy())\n",
    "ax.set_xticks(np.arange(len(pivot_mean.columns)))\n",
    "ax.set_yticks(np.arange(len(pivot_mean.index)))\n",
    "ax.set_xticklabels(pivot_mean.columns)\n",
    "ax.set_yticklabels(pivot_mean.index)\n",
    "ax.set_ylabel(\"True Target\")\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_title(\"Mean (std) of Annotations\")\n",
    "plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "for i in range(len(pivot_mean.index)):\n",
    "    for j in range(len(pivot_mean.columns)):\n",
    "        text = ax.text(j, i, str(round(pivot_mean.to_numpy()[i, j], 2)) + \" (\" + str(round(pivot_std.to_numpy()[i, j], 2)) + \")\",\n",
    "                       ha=\"center\", va=\"center\", color=\"w\" if round(pivot_mean.to_numpy()[i, j], 2) < 3.5 else \"black\")\n",
    "\n",
    "plt.savefig(\"predicted_vs_true__target_shown.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a865f",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "We notice that the perceived quality of rationales is significantly worse if we show the true target 'Yes' together with rationales that were generated alongside a wrong prediction. However, this does not indicate faithfulness as we would need to observe higher ratings if the prediction is shown instead of the true targets. For more, see the next graphic.\n",
    "\n",
    "We again observe that correctly identified targets 'Yes' lead to higher rated rationales than correctly identified targets 'No'. This again shows that the model appears to be better at generating positive rationales.\n",
    "\n",
    "Annotations for a wrongly predicted target 'in the middle' are perceived much better if the true target is 'No' than if the true target is 'Yes'. Especially considering that before we found that if the correct target is 'in the middle', showing rationales with the wrongly predicted target 'Yes' leads to a higher perceived rationale quality than showing rationales with the wrongly predicted label 'No', this result is surprising (we can also observe this in the top row). However, we are again unable to draw definite conclusions from this due to the inability to judge whether annotators rated faithfulness to the shown targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9374f6",
   "metadata": {},
   "source": [
    "### The following graphic depicts annotations by true target vs. prediction if the prediction is shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "id": "01164e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pivot_mean = pd.pivot_table(data.loc[(data['corr_target_shown'] == False) | (data['correct_pred'] == True)],\n",
    "                                values='normalized_annotation',\n",
    "                                index='target',\n",
    "                                columns='prediction',\n",
    "                                aggfunc=np.mean)\n",
    "pivot_std = pd.pivot_table(data[data['corr_target_shown'] == False  | (data['correct_pred'] == True)], values='normalized_annotation', index='target', columns='prediction',\n",
    "                           aggfunc=np.std)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(pivot_mean.to_numpy())\n",
    "ax.set_xticks(np.arange(len(pivot_mean.columns)))\n",
    "ax.set_yticks(np.arange(len(pivot_mean.index)))\n",
    "ax.set_xticklabels(pivot_mean.columns)\n",
    "ax.set_yticklabels(pivot_mean.index)\n",
    "ax.set_ylabel(\"True Target\")\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_title(\"Mean (std) of Annotations\")\n",
    "plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "for i in range(len(pivot_mean.index)):\n",
    "    for j in range(len(pivot_mean.columns)):\n",
    "        text = ax.text(j, i, str(round(pivot_mean.to_numpy()[i, j], 2)) + \" (\" + str(round(pivot_std.to_numpy()[i, j], 2)) + \")\",\n",
    "                       ha=\"center\", va=\"center\", color=\"w\" if round(pivot_mean.to_numpy()[i, j], 2) < 3.5 else \"black\")\n",
    "    \n",
    "plt.savefig(\"predicted_vs_true__prediction_shown.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e86f26",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "We note that the ratings in the bottom left quadrant have significantly increased over showing the true target. This indicates that the model is faithful towards predictions 'in the middle' when the true target is 'Yes'. However the ratings in the bottom middle quadrant remain roughly the same as in case we show the true prediction. This could mean that there is no apparent faithfulness in case the model produces a wrong prediction 'No' for a true target 'Yes'. However, this could also result from the annotators not only considering the rationale quality towards the shown target but also the quality of the target. In this case, the shown target 'No' likely does not fit very well with the true target 'Yes'.\n",
    "\n",
    "The quadrant corresponding to the prediction 'in the middle' and true target 'No' indicates that if the model is indeed better at generating positive rationales than negative ones, rationales for the prediction 'in the middle' are closer to positive rationales than to negative ones. \n",
    "\n",
    "Considering the graphic shown before, we can now make some rather definite conclusions regarding the model being better at generating positive rationales than negative ones. We have already observed that correctly predicted targets 'Yes' receive higher rationale ratings than correctly predicted targets 'No'. We now also see that if the model wrongly predicts the target 'No' instead of the true target 'Yes', the rationales are of higher quality if the true target 'Yes' is shown to the annotators. At the same time, if the model predicts the target 'Yes' instead of the true target 'No', the rationales are of higher quality if the wrong prediction 'Yes' is shown to the annotators. Both results combined rule out faithfulness as a possible reason for this.\n",
    "\n",
    "We can make multiple interesting observations from the top row. First, we notice that if we show the model prediction instead of the true target 'in the middle', the perceived quality of rationales is higher for model prediction 'Yes' than for model prediction 'No'. From the previous graphic, we know that if the correct target is 'in the middle', showing rationales with the wrongly predicted target 'Yes' leads to a higher perceived rationale quality than showing rationales with the wrongly predicted label 'No'. Considering both graphics jointly, we see that if we switch from showing the true target to showing the model prediction, the perceived quality of rationales goes up for model predictions 'No' and goes down for model predictions 'Yes'. However, this again could be because annotators did not purely evaluate faithfulness towards the shown prediction but instead evaluated both prediction and rationale. If the model tends to produce rationales that are more fitting for polar labels instead of 'in the middle' and instances with true target 'in the middle' are conceptually closer to the target 'No' than to the target 'Yes', we would observe a similar behavior. This would however not explain why the ratings for rationales under a prediction 'Yes' are higher than the ones under a prediction 'No'. Most likely, there is a more complex interplay at action that we have not observed with the setup of our survey."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a5000d",
   "metadata": {},
   "source": [
    "### Aggregation by correct prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "69291e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">annotation</th>\n",
       "      <th colspan=\"3\" halign=\"left\">normalized_annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct_pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2.103825</td>\n",
       "      <td>1.368860</td>\n",
       "      <td>183</td>\n",
       "      <td>2.214789</td>\n",
       "      <td>1.297737</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3.256410</td>\n",
       "      <td>1.509475</td>\n",
       "      <td>117</td>\n",
       "      <td>3.445006</td>\n",
       "      <td>1.470098</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             annotation                 normalized_annotation                \n",
       "                   mean       std count                  mean       std count\n",
       "correct_pred                                                                 \n",
       "False          2.103825  1.368860   183              2.214789  1.297737   183\n",
       "True           3.256410  1.509475   117              3.445006  1.470098   117"
      ]
     },
     "execution_count": 976,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['correct_pred']).agg(\n",
    "        {'annotation': ['mean', 'std', 'count'], 'normalized_annotation': ['mean', 'std', 'count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f771b3",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "Unsurprisingly, we note that if the model makes a correct prediction, the perceived quality of the rationales is higher than when the model makes a wrong prediction. This is mainly because in this case the whole output of the model fits to the input. Further, the annotators not purely evaluating faithfulness but also the prediction could play a role here. Lastly, we note that there have been no correct predictions for the label 'in the middle' and since we suspect that polar labels are easier to rationalize, this could play a further role in the results shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235f339",
   "metadata": {},
   "source": [
    "## Worker analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9ead3",
   "metadata": {},
   "source": [
    "First, we look at how often the different ratings were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "ef253764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    111\n",
       "2     62\n",
       "5     52\n",
       "4     46\n",
       "3     29\n",
       "Name: annotation, dtype: int64"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9766a0",
   "metadata": {},
   "source": [
    "We calculate the normalized mean annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "7333850d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.694573329020269"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['normalized_annotation'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f2d6e",
   "metadata": {},
   "source": [
    "We calculate the unnormalized mean annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "fefd7a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5533333333333332"
      ]
     },
     "execution_count": 979,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annotation'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2df629",
   "metadata": {},
   "source": [
    "We see the normalized mean is not too different from the unnormalized mean, which is what we expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdfd68d",
   "metadata": {},
   "source": [
    "For future reference (if we choose to make a follow-up survey), we now investigate the annotation time required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "baca3448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotation_times = data['WorkTimeInSeconds'].to_numpy()\n",
    "sns.histplot(annotation_times, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a1528",
   "metadata": {},
   "source": [
    "We observe that most annotations take less than 100 seconds. Thus, we will treat all annotations which took more than 100 seconds as outliers and remove them from our further computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "10095a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotation_times = data[data['WorkTimeInSeconds'] <= 100]['WorkTimeInSeconds'].to_numpy()\n",
    "sns.histplot(annotation_times, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016d988",
   "metadata": {},
   "source": [
    "We calculate the 75th percentile and use that as a reference time for future annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "6e04b6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 982,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(annotation_times, q=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22821ffc",
   "metadata": {},
   "source": [
    "We see that this roughly equals the initially stated 30 seconds of time that is required per annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3dc584",
   "metadata": {},
   "source": [
    "## Krippendorff's alpha:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ec64b",
   "metadata": {},
   "source": [
    "To evaluate inter-worker aggreement, we use Krippendorff's alpha, which, in contrast to Cohen's beta, is able to consider missing values. In our dataset, missing values come in form of not every annotator having evaluated every sample.\n",
    "\n",
    "We suspect that the Likert scale in our case is an interval scale, yet we report both the Krippendorff's alpha for nominal and interval scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "937f2263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's alpha nominal: 0.17546278639950708\n",
      "Krippendorff's alpha interval: 0.4576422082992134\n"
     ]
    }
   ],
   "source": [
    "agg_data = data.copy()\n",
    "agg_data['dummy_id'] = agg_data['id'].astype(str) + agg_data['corr_target_shown'].astype(str)\n",
    "agg_data = agg_data.pivot(index='WorkerId', columns='dummy_id', values='annotation')\n",
    "agg_data = agg_data.fillna('*')\n",
    "ka_nominal = krippendorff_alpha(agg_data.to_numpy(), nominal_metric, missing_items='*')\n",
    "ka_interval = krippendorff_alpha(agg_data.to_numpy(), interval_metric, missing_items='*')\n",
    "print(f\"Krippendorff\\'s alpha nominal: {ka_nominal}\")\n",
    "print(f\"Krippendorff\\'s alpha interval: {ka_interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40596f68",
   "metadata": {},
   "source": [
    "We see that in the interval case, annotators tend to agree systematically which makes the survey results valid to be used for analysis. The nominal Krippendorff's alpha is significantly lower, but as our items in the Likert scale are at least ordinal, the nominal Krippendorff's alpha is less expressive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60533846",
   "metadata": {},
   "source": [
    "## LAS Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c1971",
   "metadata": {},
   "source": [
    "We now evaluate whether human evaluations roughly correspond to the scores whe have received from the leakage-adjusted simulatablility model.\n",
    "\n",
    "For this, we first examine the pearson correlation coefficient between the normalized annotations and the LAS score, the simulator correctness based on input and explanation, the simulator correctness based on the explanation only and the simulator correctness based on the input only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "id": "b2f96cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrcoeff (annotation, LAS_score): -0.0053  p: 0.9265\n",
      "corrcoeff (annotation, XE_correct): 0.0947  p: 0.1015\n",
      "corrcoeff (annotation, E_correct): 0.0511  p: 0.3774\n",
      "corrcoeff (annotation, X_correct): 0.0815  p: 0.1592\n"
     ]
    }
   ],
   "source": [
    "c_LAS = pearsonr(data['normalized_annotation'].to_numpy(), data['LAS_score'].to_numpy())\n",
    "c_XE = pearsonr(data['normalized_annotation'].to_numpy(), data['XE_correct'].to_numpy())\n",
    "c_E = pearsonr(data['normalized_annotation'].to_numpy(), data['E_correct'].to_numpy())\n",
    "c_X = pearsonr(data['normalized_annotation'].to_numpy(), data['X_correct'].to_numpy())\n",
    "\n",
    "print(f\"corrcoeff (annotation, LAS_score): {c_LAS[0]:0.4f}  p: {c_LAS[1]:0.4f}\")\n",
    "print(f\"corrcoeff (annotation, XE_correct): {c_XE[0]:0.4f}  p: {c_XE[1]:0.4f}\")\n",
    "print(f\"corrcoeff (annotation, E_correct): {c_E[0]:0.4f}  p: {c_E[1]:0.4f}\")\n",
    "print(f\"corrcoeff (annotation, X_correct): {c_X[0]:0.4f}  p: {c_X[1]:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ba916",
   "metadata": {},
   "source": [
    "It appears that the correlation is only minor, paired with high probabilities to observe that data under the null hypothesis of no correlation. We therefore replicate one of the analyses from the [LAS Paper](https://arxiv.org/abs/2010.04119) given in Table 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "05364072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           normalized_annotation          \n",
      "                            mean       std\n",
      "XE_correct                                \n",
      "False                   2.412470  1.404373\n",
      "True                    2.765099  1.507151\n",
      "          normalized_annotation          \n",
      "                           mean       std\n",
      "X_correct                                \n",
      "False                  2.578005  1.477083\n",
      "True                   2.820855  1.502051\n",
      "          normalized_annotation          \n",
      "                           mean       std\n",
      "E_correct                                \n",
      "False                  2.608655  1.452351\n",
      "True                   2.762081  1.522605\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby(['XE_correct']).agg({'normalized_annotation':['mean', 'std']}))\n",
    "print(data.groupby(['X_correct']).agg({'normalized_annotation':['mean', 'std']}))\n",
    "print(data.groupby(['E_correct']).agg({'normalized_annotation':['mean', 'std']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "8b3a0007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinregressResult(slope=0.352628969507008, intercept=2.4124701534146626, rvalue=0.09472298701424281, pvalue=0.1015292079173724, stderr=0.2146828422390695)\n",
      "\n",
      "LinregressResult(slope=0.24285017655924498, intercept=2.5780052442718313, rvalue=0.0814775796443099, pvalue=0.15922493293400716, stderr=0.17208610823295536)\n",
      "\n",
      "LinregressResult(slope=0.1534258090765738, intercept=2.6086548759373875, rvalue=0.05114417521980431, pvalue=0.3773860433011088, stderr=0.1735503000377465)\n"
     ]
    }
   ],
   "source": [
    "print(linregress(data['XE_correct'].to_numpy(), data['normalized_annotation'].to_numpy()))\n",
    "print()\n",
    "print(linregress(data['X_correct'].to_numpy(), data['normalized_annotation'].to_numpy()))\n",
    "print()\n",
    "print(linregress(data['E_correct'].to_numpy(), data['normalized_annotation'].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bbf460",
   "metadata": {},
   "source": [
    "We see that in principle the observations are comparable: there appear to be similar effects between the simulator accuracies and the annotations as reported in Table 5 of the LAS paper.\n",
    "\n",
    "However, the magnitude of the coefficients when predicting the annotations from the accuracy of the simulators is different. While the authors of the LAS paper observe the highest coefficient for predicting annotations from simulator accuracy based on the explanation, we observe the highest coefficient when predicting from both input and explanation. At the same time, however, our $p$-values do not support definite conclusions, which again could be due to the very small number of annotations that are at our disposal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f938cd",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f6f26",
   "metadata": {},
   "source": [
    "The analyses have shown trends in the model behavior of which we believe some to be systematic, such as the better performance on producing positive rationales over negative rationales and the model being faithful to (a subset of) its predictions. However, the very small number of annotations paired with the in hindsight insufficient information we have received from the annotators about the qualities of a shown sample keep us short of making any definite conclusions. \n",
    "\n",
    "As most of the observations made here are either not robust enough or irrelevant towards our original research question, we decided to exclude them from our project report in order to keep the focus on results we can draw actual conclusions from.\n",
    "\n",
    "For future work, we should re-design the setup of the Mechanical Turk survey to obtain more reliable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1a935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cdm)",
   "language": "python",
   "name": "cdm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
